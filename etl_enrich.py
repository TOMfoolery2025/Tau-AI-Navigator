import requests
import json
import time
from neo4j import GraphDatabase

def fetch_landmarks():
    """Fetch top tourist POIs (Museums, Attractions) in Helsinki via Overpass API"""
    overpass_url = "http://overpass-api.de/api/interpreter"
    overpass_query = """
    [out:json];
    (
      node["tourism"="museum"](60.15,24.90,60.20,24.98);
      node["tourism"="attraction"](60.15,24.90,60.20,24.98);
      node["historic"="castle"](60.15,24.90,60.20,24.98);
      node["religion"="cathedral"](60.15,24.90,60.20,24.98);
    );
    out body;
    """
    response = requests.get(overpass_url, params={'data': overpass_query})
    data = response.json()
    return data.get('elements', [])

def run_enrichment(driver):
    print("ðŸš€ Starting Semantic Enrichment...")
    
    # 1. Fetch External Data
    landmarks = fetch_landmarks()
    print(f"   Found {len(landmarks)} landmarks from OpenStreetMap.")

    with driver.session() as session:
        # 2. Initialize Neosemantics (n10s) Config
        # This tells Neo4j to handle RDF URIs and treat them as properties where possible
        session.run("CREATE CONSTRAINT n10s_unique_uri IF NOT EXISTS FOR (r:Resource) REQUIRE r.uri IS UNIQUE")
        session.run("CALL n10s.graphconfig.init({ handleVocabUris: 'IGNORE' })") 

        # 3. Import the RDF File (Generated by your existing etl_rdf.py)
        # Note: We assume etl_rdf.py saved 'helsinki_graph.ttl' to the shared volume
        print("   Importing RDF Turtle file...")
        session.run("""
        CALL n10s.rdf.import.fetch("file:///var/lib/neo4j/import/helsinki_graph.ttl", "Turtle")
        """)

        # 4. Import Landmarks as 'PointOfInterest' Nodes
        print("   Creating Landmark Nodes...")
        landmark_query = """
        UNWIND $batch AS row
        MERGE (p:PointOfInterest {id: row.id})
        SET p.name = row.tags.name,
            p.type = row.tags.tourism,
            p.lat = row.lat,
            p.lon = row.lon,
            p.location = point({latitude: row.lat, longitude: row.lon})
        """
        # Filter only items with names
        valid_pois = [x for x in landmarks if 'tags' in x and 'name' in x['tags']]
        session.run(landmark_query, batch=valid_pois)

        # 5. REASONING STEP: Spatial Linkage
        # Link GTFS Stops (from etl_neo4j.py) to these new Landmarks
        print("   Inferring 'IS_NEAR' relationships (Reasoning)...")
        session.run("""
        MATCH (s:Stop)
        WHERE s.lat IS NOT NULL AND s.lon IS NOT NULL
        WITH s, point({latitude: s.lat, longitude: s.lon}) AS stopPoint
        
        MATCH (p:PointOfInterest)
        WHERE point.distance(p.location, stopPoint) < 400 // 400 meters walk
        
        MERGE (s)-[r:IS_NEAR]->(p)
        SET r.distance_m = toInteger(point.distance(p.location, stopPoint))
        """)
        
        # 6. REASONING STEP: Tourist Route Classification
        # If a route stops near a Museum, label it as 'TouristRoute'
        print("   Classifying Tourist Routes...")
        session.run("""
        MATCH (r:Route)-[:OPERATES_ON]->(s:Stop)-[:IS_NEAR]->(p:PointOfInterest)
        WHERE p.type IN ['museum', 'attraction']
        MERGE (r)-[:RDF_TYPE]->(:Class {name: 'TouristFriendlyRoute'})
        SET r:TouristRoute
        """)

    print("âœ… Enrichment Complete: Graph is now spatially and semantically linked!")